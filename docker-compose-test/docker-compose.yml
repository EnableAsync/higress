version: '3.7'
services:
  envoy:
    # image: higress-registry.cn-hangzhou.cr.aliyuncs.com/higress/gateway:v1.4.0-rc.1
    image: higress-registry.cn-hangzhou.cr.aliyuncs.com/higress/gateway:1.4.2
    entrypoint: /usr/local/bin/envoy
    # 注意这里对wasm开启了debug级别日志，正式部署时则默认info级别
    command: -c /etc/envoy/envoy.yaml --component-log-level wasm:debug
    depends_on:
    - httpbin
    - redis
    - chroma
    networks:
    - wasmtest
    ports:
    - "10000:10000"
    - "9901:9901"
    volumes:
    - ./envoy.yaml:/etc/envoy/envoy.yaml
    # 注意默认没有这两个 wasm 的时候，docker 会创建文件夹，这样会出错，需要有 wasm 文件之后 down 然后重新 up
    - ./ai-cache.wasm:/etc/envoy/ai-cache.wasm
    - ./ai-proxy.wasm:/etc/envoy/ai-proxy.wasm

  chroma:
    image: chromadb/chroma
    ports:
      - "8001:8000"
    volumes:
      - chroma-data:/chroma/chroma

  redis:
    image: redis:latest
    networks:
    - wasmtest
    ports:
    - "6379:6379"

  httpbin:
    image: kennethreitz/httpbin:latest
    networks:
    - wasmtest
    ports:
    - "12345:80"

  lobechat:
    # docker hub 如果访问不了，可以改用这个地址：registry.cn-hangzhou.aliyuncs.com/2456868764/lobe-chat:v1.1.3
    image: lobehub/lobe-chat
    environment:
      - CODE=admin
      - OPENAI_API_KEY=unused
      - OPENAI_PROXY_URL=http://envoy:10000/v1
    networks:
      - wasmtest
    ports:
      - "3210:3210/tcp"

  # weaviate:
  #   command:
  #   - --host
  #   - 0.0.0.0
  #   - --port
  #   - '8080'
  #   - --scheme
  #   - http
  #   image: cr.weaviate.io/semitechnologies/weaviate:1.26.1
  #   ports:
  #   - 8081:8080
  #   - 50051:50051
  #   volumes:
  #   - weaviate_data:/var/lib/weaviate
  #   restart: on-failure:0
  #   networks:
  #   - wasmtest
  #   environment:
  #     QUERY_DEFAULTS_LIMIT: 25
  #     AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
  #     PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
  #     DEFAULT_VECTORIZER_MODULE: 'none'
  #     ENABLE_API_BASED_MODULES: 'true'
  #     CLUSTER_HOSTNAME: 'node1'
  #     TRANSFORMERS_INFERENCE_API: http://t2v-transformers:8080  # Set the inference API endpoint

  # t2v-transformers:  # Set the name of the inference container
  #   image: cr.weaviate.io/semitechnologies/transformers-inference:sentence-transformers-multi-qa-MiniLM-L6-cos-v1
  #   environment:
  #     ENABLE_CUDA: 0  # Set to 1 to enable
volumes:
  weaviate_data: {}
  chroma-data:
    driver: local

networks:
  wasmtest: {}